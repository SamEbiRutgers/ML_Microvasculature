{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Code4-Prediction of simultaneous spatial and temporal variations.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyNEWL/ZVVSM4NZNDC0cN4OG"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"OtGY5jjz5nxL","executionInfo":{"status":"ok","timestamp":1656430243112,"user_tz":240,"elapsed":3245,"user":{"displayName":"Saman Ebrahimi","userId":"01307570353570623759"}}},"outputs":[],"source":["import tensorflow as tf\n","import numpy as np\n","from os import path, getcwd, chdir\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import csv\n","import tarfile\n"]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from pandas.plotting import autocorrelation_plot\n","from sklearn.preprocessing import MinMaxScaler\n","\n","def DATA(file1,file2,W):\n","  dd=100\n","  \n","  file=file1\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","\n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  uu=np.zeros((len(Y1)-dd,1))\n","  uu[:,0]=Y1[dd:]\n","\n","  \n","  X_Data=np.zeros((len(Y1)-W,W))\n","  for i in range(len(Y1)-W):\n","    for j in range(i,i+W):\n","      X_Data[i,j-i]=Y1[j]\n","\n","  file=file2\n","  \n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","\n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  vv=np.zeros((len(Y1)-dd,1))\n","  vv[:,0]=Y1[dd:]\n","\n","  \n","  Y_Data=np.zeros((len(Y1)-W,W))\n","  for i in range(len(Y1)-W):\n","    for j in range(i,i+W):\n","      Y_Data[i,j-i]=Y1[j]\n","\n","  xx = np.reshape(uu, [len(uu),])\n","  yy = np.reshape(vv, [len(vv),])\n","\n","  \n","  return(X_Data,Y_Data)"],"metadata":{"id":"eZkx9QGG752M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","from pandas.plotting import autocorrelation_plot\n","from sklearn.preprocessing import MinMaxScaler\n","\n","def DATA2(file1,file2,file3,W):\n","  dd=100\n","\n","  file=file1\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","\n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  uu=np.zeros((len(Y1)-dd,1))\n","  uu[:,0]=Y1[dd:]\n","\n","\n","  X_Data=np.zeros((len(Y1)-W,W))\n","  for i in range(len(Y1)-W):\n","    for j in range(i,i+W):\n","      X_Data[i,j-i]=Y1[j]\n","\n","  file=file2\n"," \n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  Y1x=[]\n","  X1=[]\n","  for x in lines:\n","    X1.append(float(x.split()[0]))\n","    Y1x.append(float(x.split()[1]))\n","\n","\n","  file=file3\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  Y2x=[]\n","  X1=[]\n","  for x in lines:\n","    X1.append(float(x.split()[0]))\n","    Y2x.append(float(x.split()[1]))\n","\n","  Ynew_Data=np.zeros((len(Y1)-W,W,2))\n","  for i in range(len(Y1)-W):\n","      for j in range(i,i+W):\n","\n","        Ynew_Data[i,(j-i),0]=Y1x[j]\n","        Ynew_Data[i,(j-i),1]=Y2x[j]\n","\n","  return(X_Data,Ynew_Data)"],"metadata":{"id":"FHEI8yOo7-LH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def G8_relation():\n","  df = pd.read_csv (r'G8FBCinfo.csv')\n","  print (df)\n","  Diameter=np.zeros((len(df)+1,1))\n","  Q=np.zeros((len(df)+1,1))\n","\n","  Di=df['Diii']\n","  volumeflow=df['vol_florate Ca=1']\n","  for i in range(len(df)):\n","    Diameter[i+1,0]=Di[i]\n","    Q[i+1,0]=volumeflow[i]\n","\n","  BIF = pd.read_csv (r'bif_relation8.csv')\n","  BIF1=BIF['mother']\n","  BIF2=BIF['daughter1']\n","  BIF3=BIF['daughter2'] \n","\n","  mother=np.zeros((len(BIF1)+1,1))\n","  daughter1=np.zeros((len(BIF1)+1,1))\n","  daughter2=np.zeros((len(BIF1)+1,1))\n","  for i in range(len(BIF1)):\n","    mother[i+1,0]=BIF1[i]\n","    daughter1[i+1,0]=BIF2[i]\n","    daughter2[i+1,0]=BIF3[i]\n","  return(mother,daughter1,daughter2,BIF1,BIF2,BIF3,Q)"],"metadata":{"id":"Pq1ydoNX8We3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#generating model for prediction of daughter vessel quantity from mother vessel quantity \n","import numpy as np\n","from scipy.stats import kurtosis\n","from scipy.stats import skew\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","\n","mother,daughter1,daughter2,BIF1,BIF2,BIF3,Q=G8_relation()\n","model_store=[]\n","\n","# for each mother vessel you need to have time window \n","# time window can be obtained from method described in section 3.3 \n","window=[[2,50],\n","[4,40],\n","[5,100],\n","[6,40],\n","[7,80],\n","[8,80],\n","[9,100],\n","[10,30],\n","[11,90],\n","[12,80],\n","[13,100],\n","[14,50],\n","[15,110],\n","[16,100],\n","[17,70],\n","[18,50],\n","[19,100],\n","[20,60],\n","[21,120]]\n","\n","#matching_bif=16\n","\n","# bi identify the bifurcation we are working on \n","for bi in range(1,22):\n","  if bi !=3 :\n","    for ss in range(len(window)):\n","      if bi == window[ss][0]:\n","        W=window[ss][1]\n","    ST=[]\n","    SK=[]\n","    KU=[]\n","    for mm in range(matching_bif,matching_bif+1):\n","      print('bif=',bi,'W=',W)\n","      for i in range(len(BIF1)+1):\n","        if i==bi:\n","          mom=mother[i,0]\n","          dau1=daughter1[i,0]\n","          dau2=daughter2[i,0]\n","          d1=0\n","          d2=0\n","          m=mom\n","          if Q[int(dau1),0]/Q[int(mom),0]>Q[int(dau2),0]/Q[int(mom),0]:\n","            d1=dau1\n","            d2=dau2\n","          elif Q[int(dau1),0]/Q[int(mom),0]<Q[int(dau2),0]/Q[int(mom),0]:\n","            d1=dau2\n","            d2=dau1\n","        \n","          file1='fort.'+str(6001+int(10*m))\n","          file2='fort.'+str(6001+int(10*d1))\n","          file3='fort.'+str(6001+int(10*d2))\n","          print('mother',mother[i,0], 'daugther1,2',daughter1[i,0],daughter2[i,0],'biger_Q',d1,file1,file2)\n","\n","      X_Data,Y_Data=DATA2(file1,file2,file3,W)\n","\n","      X_Data=np.reshape(X_Data,(X_Data.shape[0],X_Data.shape[1],1))\n","      Y_Data=np.reshape(Y_Data,(Y_Data.shape[0],Y_Data.shape[1],2))\n","\n","      model = Sequential()\n","\n","      model.add(LSTM(units=100, return_sequences=True, input_shape=(W,1)))\n","      model.add(Dropout(0.1))\n","\n","      model.add(LSTM(units=100, return_sequences=True))\n","      model.add(Dropout(0.1))\n","\n","      model.add(LSTM(units=100, return_sequences=True))\n","      model.add(Dropout(0.1))\n","\n","      model.add(Dense(units = W))\n","\n","      model.compile(optimizer='adam',\n","                            loss='mse',\n","                            metrics=['mse'])\n","      model.summary()\n","      history = model.fit(\n","                    X_Data, Y_Data, epochs=3000            \n","          )\n","\n","      model_store.append([W,model])\n","  "],"metadata":{"id":"QF2_ULXm8cXL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["number_bif =21\n","for i in range(number_bif):\n","  model_store[i].save('TwoBif_Bif'+str(i+1)+'/my_model') \n","model.save('HtTwobif'+str(4)+'/my_model') "],"metadata":{"id":"6mkiZmka-uYr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#untar the saved models\n","!tar -xvf TwoBif_Bif1.tar.gz\n","!tar -xvf TwoBif_Bif2.tar.gz\n","!tar -xvf TwoBif_Bif3.tar.gz\n","!tar -xvf TwoBif_Bif4.tar.gz\n","!tar -xvf TwoBif_Bif5.tar.gz\n","!tar -xvf TwoBif_Bif6.tar.gz\n","!tar -xvf TwoBif_Bif7.tar.gz\n","!tar -xvf TwoBif_Bif8.tar.gz\n","!tar -xvf TwoBif_Bif9.tar.gz\n","!tar -xvf TwoBif_Bif10.tar.gz\n","!tar -xvf TwoBif_Bif11.tar.gz\n","!tar -xvf TwoBif_Bif12.tar.gz\n","!tar -xvf TwoBif_Bif13.tar.gz\n","!tar -xvf TwoBif_Bif14.tar.gz\n","!tar -xvf TwoBif_Bif15.tar.gz\n","!tar -xvf TwoBif_Bif16.tar.gz\n","!tar -xvf TwoBif_Bif17.tar.gz\n","!tar -xvf TwoBif_Bif18.tar.gz\n","!tar -xvf TwoBif_Bif19.tar.gz\n","!tar -xvf TwoBif_Bif20.tar.gz\n","!tar -xvf TwoBif_Bif21.tar.gz"],"metadata":{"id":"n96t0iTn_Rcc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#info1 shows time window for each bifurcation \n","info1=[[2,50],\n","[4,40],\n","[5,100],\n","[6,40],\n","[7,80],\n","[8,80],\n","[9,100],\n","[10,30],\n","[11,90],\n","[12,80],\n","[13,100],\n","[14,50],\n","[15,110],\n","[16,100],\n","[17,70],\n","[18,50],\n","[19,100],\n","[20,60],\n","[21,120]]\n","modelss=[]\n","for j in range(len(info1)):\n","    print(j)\n","    modelss.append([info1[j][0],tf.keras.models.load_model('content/Twobif'+str(info1[j][0])+'/my_model')])"],"metadata":{"id":"MLHO9-gC_pYu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# extend the quantity of interest over time based on what we discuss in the section 3.3\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","import random\n","\n","import csv\n","import numpy as np\n","from scipy.stats import kurtosis\n","from scipy.stats import skew\n","import sys\n","\n","#------->define mother vessel \n","bi = 10  #give the bifurcation that you want to work on them  \n","for i in range(len(BIF1)+1):\n","  if i==bi:\n","    \n","    mom=mother[i,0]\n","    dau1=daughter1[i,0]\n","    dau2=daughter2[i,0]\n","    d1=0\n","    d2=0\n","    m=mom\n","    if Q[int(dau1),0]/Q[int(mom),0]>Q[int(dau2),0]/Q[int(mom),0]:\n","      d1=dau1\n","      d2=dau2\n","    elif Q[int(dau1),0]/Q[int(mom),0]<Q[int(dau2),0]/Q[int(mom),0]:\n","      d1=dau2\n","      d2=dau1\n","    file1='fort.'+str(5001+int(10*m))\n","    file2='fort.'+str(5001+int(10*d1))\n","    file3='fort.'+str(5001+int(10*d2))\n","\n","print('file1',file1)\n","\n","\n","dd=100\n","\n","EPO=500\n","window=0\n","Sk=[]\n","Kt=[]\n","Me=[]\n","St=[]\n","Res=[]\n","file = file1\n","for io in range (1):\n","  \n","  window = 450 # obtained time window from code1-....\n","  print('window = ',window)\n","  #####\n","  \n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","  \n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  apple_training_processed=np.zeros((len(Y1)-dd,1))\n","  apple_training_processed[:,0]=Y1[dd:]\n","\n","  scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","  apple_training_scaled = scaler.fit_transform(apple_training_processed)\n","\n","  features_set = []\n","  labels = []\n","  for i in range(0, len(apple_training_scaled)-1-2*window):\n","      features_set.append(apple_training_scaled[i:i+window, 0])\n","      labels.append(apple_training_scaled[i+window:i+2*window, 0])\n","\n","\n","  features_set, labels = np.array(features_set), np.array(labels)\n","\n","\n","  features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n","  labels = np.reshape(labels, (labels.shape[0], labels.shape[1], 1))\n","\n","\n","  model = Sequential()\n","\n","  model.add(LSTM(units=100, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n","  model.add(Dropout(0.1))\n","\n","\n","  model.add(LSTM(units=100, return_sequences=True))\n","  model.add(Dropout(0.1))\n","\n","\n","  model.add(LSTM(units=100, return_sequences=True))\n","  model.add(Dropout(0.1))\n","\n","\n","  model.add(Dense(units = 1))\n","  model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","  model.summary()\n","  history=model.fit(features_set, labels, epochs = EPO, batch_size = 32,callbacks=[EarlyStoppingByLossVal()])\n","\n","\n","\n","  from sklearn.preprocessing import MinMaxScaler\n","\n","\n","  #file = 'fort.5061'\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","  \n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  data_actual=np.zeros((len(Y1)-dd,1))\n","  data_actual[:,0]=Y1[dd:]\n","\n","  #######\n","  plt.plot(data_actual[:], color='blue', label='Actual Apple Stock Price')\n","\n","\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","  \n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  data=np.zeros((len(Y1)-dd,1))\n","  data[:,0]=Y1[dd:]\n","\n","  #######\n","  print('SGH',np.shape(data))\n","\n","  only_pred=[]\n","  for iter in range(6):\n","    print('iter',iter)\n","    scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","    data_scaled = scaler.fit_transform(data)\n","    data_set = []\n","    for i in range(0, len(data)-2*window-1):\n","        data_set.append(data_scaled[i:i+window, 0])\n","\n","    data_set = np.array(data_set)\n","    data_set=np.reshape(data_set,(data_set.shape[0], data_set.shape[1], 1))\n","\n","\n","    pred_scaled=model.predict(data_set[len(data_set)-1,:,:].reshape(1,window,1))\n","    #print('jjjj',pred_scaled[0])\n","    data=np.array(data)\n","    data=data.tolist()\n","    \n","    for i in range(len(pred_scaled[0])):\n","      ff=pred_scaled[0,i][0]\n","      ff=ff.reshape(-1, 1)\n","      pred = scaler.inverse_transform(ff)\n","  \n","      data.append([pred[0,0]])\n","      only_pred.append([pred[0,0]])\n","\n","      \n","\n","    data=np.array(data)\n","\n","  # You can sketch your predicted curve in time with original curve and also compare the statisticals  \n","  plt.plot(data[:] , color='red', label='Predicted Apple Stock Price')\n","  plt.plot(data_actual[:], color='blue', label='Actual Apple Stock Price')\n","\n","  Sk.append((window,skew(data[len(uu):])))\n","  Kt.append((window,kurtosis(data[len(uu):])))\n","  Me.append((window,np.mean(data[len(uu):])))\n","  St.append((window,np.std(data[len(uu):])))\n","  print('window',window,'skewness=',skew(data),'kurtosis=',kurtosis(data))\n","  print('window',window,'True skewness=',skew(data_actual),'Truekurtosis=',kurtosis(data_actual))\n","  print('window',window,'mean data',np.mean(data),'std data',np.std(data))\n","  print('window',window,'True mean data',np.mean(data_actual),'True std',np.std(data_actual))"],"metadata":{"id":"psyl7sleARfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Predicted the quantity of interest in each daughter vessel given that in mother vessel \n","print('first step')\n","for sa in range(len(info1)):\n","  if bi == info1[sa][0]:\n","    W=info1[sa][1]\n","\n","dd1=data\n","ff=dd1.tolist()\n","print('bi=',bi,'W=',W)\n","lo=[]\n","for i in range(len(ff)):\n","  lo.append(ff[i][0])\n","\n","f=[]\n","for j in range(1,int(len(lo)/W)):\n","  f.append(np.array(lo[(j-1)*W:W*j]))\n","\n","a1,a2=np.shape(f)\n","f2=np.zeros((a1,a2,1))\n","\n","f2[:,:,0]=f[:][:]\n","\n","nn=len(f2)\n","\n","for eb in range(len(modelss)):\n","  if bi==modelss[eb][0]:\n","    mm=modelss[eb][1]\n","\n","\n","k1=[]\n","k2=[]\n","for j in range(0,nn):\n","  pred=mm.predict(f2[j,:,:].reshape(1,W,1))\n","  pred=pred.reshape(W,2)\n","  for i in range(W):\n","    k1.append(pred[i,0])\n","    k2.append(pred[i,1])\n"],"metadata":{"id":"DB2uoeizEZC7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# plot your predicted curve in each daughter vessel and compare with the DSR of those daughter vessels \n","plt.plot(k1),plt.plot(k2)\n","plt.plot(data)\n","\n","f=open(file2,\"r\")\n","lines=f.readlines()\n","X1=[]\n","Y1=[]\n","Z1=[]\n","for x in lines:\n","    X1.append(float(x.split()[0]))\n","    Y1.append(float(x.split()[1]))\n","plt.plot(Y1)\n","f=open(file3,\"r\")\n","lines=f.readlines()\n","X11=[]\n","Y11=[]\n","Z11=[]\n","\n","for x in lines:\n","    X11.append(float(x.split()[0]))\n","    Y11.append(float(x.split()[1]))\n","plt.plot(Y11)\n","\n","print('mean d1=',np.mean(k1),'True mean d1',np.mean(Y1),'mean d2=',np.mean(k2),'True Skew d2',np.mean(Y11))\n","print('std d1=',np.std(k1),'True std d1',np.std(Y1),'std d2=',np.std(k2),'True std d2',np.std(Y11))\n","print('skewness d1=',skew(k1),'True Skew d1',skew(Y1),'skewness d2=',skew(k2),'True Skew d2',skew(Y11))\n","print('kurtosis d1=',kurtosis(k1),'True kurtosis d1',kurtosis(Y1),'kurtosis d2=',kurtosis(k2),'True kurtosis d2',kurtosis(Y11))\n","print('***************************************************************************')\n","print('Statistics----Mean')\n","print(np.mean(k1),'  ',np.mean(Y1),)\n","print(np.mean(k2),'  ',np.mean(Y11))\n","\n","print('Statistics----std')\n","print(np.std(k1),'     ',np.std(Y1))\n","print(np.std(k2),'     ',np.std(Y11))\n","\n","print('Statistics----skew')\n","print(skew(k1),'  ',skew(Y1))\n","print(skew(k2),'  ',skew(Y11))\n","\n","print('Statistics----kurtosis')\n","print(kurtosis(k1),'   ',kurtosis(Y1))\n","print(kurtosis(k2),'   ',kurtosis(Y11))"],"metadata":{"id":"nyTOWpl5ESKE"},"execution_count":null,"outputs":[]}]}