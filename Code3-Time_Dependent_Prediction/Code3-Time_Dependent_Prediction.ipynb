{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Code3-Time_Dependent_Prediction.ipynb","provenance":[{"file_id":"1gemhBZxNphKwgDrJiUkPjERgyII--qao","timestamp":1655919644675},{"file_id":"1W_Mizp8laDgMMeUvS9lFP8YDaDuXP0NH","timestamp":1625944990438},{"file_id":"1ve2xyf2Y52ywTvLzCjnX9V-QAYq8zn3y","timestamp":1625703234827},{"file_id":"1iBpeccswAKnRObfkuz5laMHMVe6tZw6n","timestamp":1624664881394},{"file_id":"1YzeGCPXqzsqf-sC7V1cDlh2vhfGojwLY","timestamp":1624285632815},{"file_id":"1Fhltu1yML1QyNzNpG4dlAProprFnvFzC","timestamp":1624241136283},{"file_id":"1IWdUsc2OjUAaCCoCEimMSgcDRPnw28Nv","timestamp":1623811366137},{"file_id":"1nIBru_Fm6XgPVr1wodhaleVZPBw2mrnn","timestamp":1623795962899},{"file_id":"1AAeK1E9bskt7nMEKde-fH02ovvAALbEn","timestamp":1623630053750}],"collapsed_sections":[],"authorship_tag":"ABX9TyPSSTDPfW9d2ovn3hSWpd4S"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"CseoGMWVFgaq"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","from pandas.plotting import autocorrelation_plot\n","\n","dd=500\n","#####\n","# real a file that you want to do the time series prediction this file has two columns X and Y\n","file = 'fort.6431'\n","f=open(file,\"r\")\n","lines=f.readlines()\n","X1=[]\n","Y1=[]\n","Z1=[]\n","\n","for x in lines:\n","    X1.append(float(x.split()[0]))\n","    Y1.append(float(x.split()[1]))\n","uu=np.zeros((len(Y1)-dd,1))\n","uu[:,0]=Y1[dd:]\n","\n","# ploting Autocorrelation for each plot \n","autocorrelation_plot(uu)\n","#####"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pwBHKsZwEr-V"},"source":["#Compute the function \n","from statsmodels.tsa.stattools import acf\n","from matplotlib import pyplot as plt\n","\n","lag_acf = acf(uu, nlags=256, fft=True)\n","plt.plot(lag_acf)\n","#plt.title('Autocorrelation Function')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"89tVyPuOkzAy"},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import pandas as pd\n","from sklearn.preprocessing import MinMaxScaler\n","\n","from keras.models import Sequential\n","from keras.layers import Dense\n","from keras.layers import LSTM\n","from keras.layers import Dropout\n","import random\n","\n","import csv\n","import numpy as np\n","from scipy.stats import kurtosis\n","from scipy.stats import skew\n","\n","EPO=900\n","window=250\n","Sk=[]\n","Kt=[]\n","Me=[]\n","St=[]\n","for io in range (10):\n","  window =io*50 +50\n","\n","  \n","  print('window = ',window)\n","\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","  \n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  apple_training_processed=np.zeros((len(Y1)-dd,1))\n","  apple_training_processed[:,0]=Y1[dd:]\n","\n","\n","  scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","  apple_training_scaled = scaler.fit_transform(apple_training_processed)\n","\n","  features_set = []\n","  labels = []\n","  for i in range(0, len(apple_training_scaled)-1-2*window):\n","      features_set.append(apple_training_scaled[i:i+window, 0])\n","      labels.append(apple_training_scaled[i+window:i+2*window, 0])\n","\n","\n","  features_set, labels = np.array(features_set), np.array(labels)\n","\n","\n","  features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n","  labels = np.reshape(labels, (labels.shape[0], labels.shape[1], 1))\n","\n","\n","  model = Sequential()\n","\n","  model.add(LSTM(units=100, return_sequences=True, input_shape=(features_set.shape[1], 1)))\n","  model.add(Dropout(0.1))\n","\n","\n","  model.add(LSTM(units=100, return_sequences=True))\n","  model.add(Dropout(0.1))\n","\n","\n","  model.add(LSTM(units=100, return_sequences=True))\n","  model.add(Dropout(0.1))\n","\n","\n","  model.add(Dense(units = 1))\n","  model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n","  model.summary()\n","  history=model.fit(features_set, labels, epochs = EPO, batch_size = 32)\n","\n","  from sklearn.preprocessing import MinMaxScaler\n","\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","  \n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  data_actual=np.zeros((len(Y1)-dd,1))\n","  data_actual[:,0]=Y1[dd:]\n","\n","  #######\n","  plt.plot(data_actual[:], color='blue', label='Actual Apple Stock Price')\n","\n","  f=open(file,\"r\")\n","  lines=f.readlines()\n","  X1=[]\n","  Y1=[]\n","  Z1=[]\n","  \n","  for x in lines:\n","      X1.append(float(x.split()[0]))\n","      Y1.append(float(x.split()[1]))\n","  data=np.zeros((len(Y1)-dd,1))\n","  data[:,0]=Y1[dd:]\n","\n","  #######\n","  print('SGH',np.shape(data))\n","  for iter in range(int(len(data_actual)/window)):\n","    print('iter',iter)\n","    scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","    data_scaled = scaler.fit_transform(data)\n","    data_set = []\n","    for i in range(0, len(data)-2*window-1):\n","        data_set.append(data_scaled[i:i+window, 0])\n","\n","    data_set = np.array(data_set)\n","    data_set=np.reshape(data_set,(data_set.shape[0], data_set.shape[1], 1))\n","\n","\n","    pred_scaled=model.predict(data_set[len(data_set)-1,:,:].reshape(1,window,1))\n","\n","    data=np.array(data)\n","    data=data.tolist()\n","    for i in range(len(pred_scaled[0])):\n","      ff=pred_scaled[0,i][0]\n","      ff=ff.reshape(-1, 1)\n","      pred = scaler.inverse_transform(ff)\n","      \n","      data.append([np.round(pred[0,0])])\n","      \n","\n","    data=np.array(data)\n","\n","  plt.plot(data[:] , color='red', label='Predicted Apple Stock Price')\n","  plt.plot(data_actual[:], color='blue', label='Actual Apple Stock Price')\n","\n","  Sk.append((window,skew(data[1308:])))\n","  Kt.append((window,kurtosis(data[1308:])))\n","  Me.append((window,np.mean(data[1308:])))\n","  St.append((window,np.std(data[1308:])))\n","  print('window',window,'skewness=',skew(data),'kurtosis=',kurtosis(data))\n","  print('window',window,'True skewness=',skew(data_actual),'Truekurtosis=',kurtosis(data_actual))\n","  print('window',window,'mean data',np.mean(data),'std data',np.std(data))\n","  print('window',window,'True mean data',np.mean(data_actual),'True std',np.std(data_actual))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BcSueB1S4_03"},"source":["plt.plot(history.history['loss'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2s8FUbSHAGkA"},"source":["file = open(\"list.txt\", \"w\")\n","for index in range(len(xx)):\n","    file.write(str(xx[index]) + \"    \" + str(yy[index]) + \"\\n\")\n","file.close()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9wCYMJEIjm5J"},"source":[" from sklearn.preprocessing import MinMaxScaler\n","\n","data_actual = pd.read_csv(r'/content/Q33.csv')\n","data_actual = data_actual.iloc[:, 1:2].values\n","plt.plot(data_actual[:], color='blue', label='Actual Apple Stock Price')\n","\n","data = pd.read_csv(r'/content/Q33.csv')\n","data = data.iloc[:, 1:2].values\n","print('SGH',np.shape(data))\n","for iter in range(int(len(data_actual)/window)):\n","  print('iter',iter)\n","  scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","  data_scaled = scaler.fit_transform(data)\n","  data_set = []\n","  for i in range(0, len(data)-2*window-1):\n","      data_set.append(data_scaled[i:i+window, 0])\n","\n","  data_set = np.array(data_set)\n","  data_set=np.reshape(data_set,(data_set.shape[0], data_set.shape[1], 1))\n","\n","\n","  pred_scaled=model.predict(data_set[len(data_set)-1,:,:].reshape(1,window,1))\n","  #print('jjjj',pred_scaled[0])\n","  data=np.array(data)\n","  data=data.tolist()\n","  for i in range(len(pred_scaled[0])):\n","    ff=pred_scaled[0,i][0]\n","    ff=ff.reshape(-1, 1)\n","    pred = scaler.inverse_transform(ff)\n","\n","    data.append([pred[0,0]])\n","    \n","\n","  data=np.array(data)\n","\n","\n","plt.plot(data[:] , color='red', label='Predicted Apple Stock Price')\n","plt.plot(data_actual[:], color='blue', label='Actual Apple Stock Price')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"twBTPM7jE8ho"},"source":["import numpy as np\n","from numpy import random  #it will be useful for generating some random noise (on purpose) in the data points that we want to fit\n","import matplotlib.pyplot as plt  #for plotting the data\n","from scipy.stats import skew\n","\n","\n","\n","fit = np.polyfit(window1,kur,2)\n","yy=fit[0]*(np.power(window1, 2))+fit[1]*(np.power(window1, 1))+fit[2]\n","print('KUR',fit)\n","print('XKUR',-fit[1]/(2*fit[0]))\n","plt.plot(window1,yy,'blue')\n","plt.scatter(window1,kur)\n","\n","fit = np.polyfit(window1,ske,2)\n","yy=fit[0]*(np.power(window1, 2))+fit[1]*(np.power(window1, 1))+fit[2]\n","print('SKE',fit)\n","print('XSKE',-fit[1]/(2*fit[0]))\n","plt.plot(window1,yy,'red')\n","plt.scatter(window1,ske)\n","plt.plot(window1,true_kur)\n","plt.plot(window1,true_ske)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0bU5Y1zk9aXA"},"source":["from pyomo.environ import *\n","\n","# create a model\n","model = ConcreteModel()\n","\n","# declare decision variables\n","model.x = Var(domain=NonNegativeReals)\n","\n","# declare objective\n","model.profit = Objective(expr = fit[0]*(model.x)^2 + fit[1]*(model.x)+fit[2] , sense=maximize)\n","\n","# declare constraints\n","model.demand = Constraint(expr = model.x >= 40)\n","model.laborA = Constraint(expr = model.x + model.y <= 80)\n","model.laborB = Constraint(expr = 2*model.x + model.y <= 100)\n","\n","model.pprint()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"S2gAu4aGX0Vy"},"source":["\n","from sklearn.preprocessing import MinMaxScaler\n","\n","data_actual = pd.read_csv(r'/content/Ht23.csv')\n","data_actual = data_actual.iloc[:, 1:2].values\n","plt.plot(data_actual[:], color='blue', label='Actual')\n","\n","data = pd.read_csv(r'/content/Ht23.csv')\n","data = data.iloc[:, 1:2].values\n","\n","for iter in range(2000):\n","  print('iter',iter)\n","  scaler = MinMaxScaler(feature_range = (0, 1))\n","\n","  data_scaled = scaler.fit_transform(data)\n","  data_set = []\n","  for i in range(window, len(data)-1):\n","      data_set.append(data_scaled[i-window:i, 0])\n","\n","  data_set = np.array(data_set)\n","  data_set=np.reshape(data_set,(data_set.shape[0], data_set.shape[1], 1))\n","\n","  pred_scaled=model.predict(data_set[len(data_set)-1,:,:].reshape(1,window,1))[0,0]\n","  #print('GGG',pred_scaled)\n","  pred_scaled=pred_scaled.reshape(-1, 1)\n","  pred = scaler.inverse_transform(pred_scaled)\n","  #print('FFFF',pred)\n","\n","  data=np.array(data)\n","  data=data.tolist()\n","\n","  data.append([np.round(pred[0,0])])\n","\n","  data=np.array(data)\n","\n","\n","plt.plot(data[:] , color='red', label='Predicted ')\n","plt.plot(data_actual[:], color='blue', label='Actual ')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6zj9e5pGqKzn"},"source":["\n","plt.plot(data[:] , color='red', label='Predicted ')\n","plt.plot(data_actual[:], color='blue', label='Actual ')\n"],"execution_count":null,"outputs":[]}]}